# AnythingFromScratchV2

Synthesic in building, testing and try new model

## Why we have AnythingFromScratchV2

Continuing the AnythingFromScratch series, you can see the previous version [here](https://github.com/DngBack/AnythingFromScratch). But since the current algorithms are quite large and require more than one file to implement, I decided to move them to this repo. This section will mainly be a link to my other repos, where I go into more depth on the algorithms.

## Structure Overview

In terms of structure, I will divide it into different contents, for example Transformers, LLM, VLM, etc. If necessary, I will divide it into smaller parts (if any). The current structure will be [Link_Implementation_Repo] Paper_Name

## List Of Paper

### Transformer

- [[RoPE](https://github.com/DngBack/AnythingFromScratch/tree/main/NLP/RoPE)] RoFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING

- [[NaViT](https://arxiv.org/pdf/2307.06304)] Patch nâ€™ Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution

- [[MLA](https://github.com/DngBack/MLA_Pytorch_Implementation)] Multi-Head Latent Attention
